[package]
name = "transcode-ai"
version.workspace = true
edition.workspace = true
authors.workspace = true
license.workspace = true
repository.workspace = true
description = "AI-powered video enhancement including upscaling, denoising, and frame interpolation"
keywords = ["video", "ai", "upscaling", "denoising", "super-resolution"]
categories = ["multimedia", "computer-vision"]

[features]
default = []
# Enable ONNX runtime for model inference
onnx = ["dep:ort"]
# Enable GPU acceleration
gpu = ["dep:transcode-gpu"]

[dependencies]
transcode-core = { path = "../transcode-core" }
transcode-gpu = { path = "../transcode-gpu", optional = true }

# Error handling
thiserror.workspace = true

# Logging
tracing.workspace = true

# Image processing
image = "0.25"
ndarray = "0.17"

# ONNX runtime (optional)
# Note: ort 2.0 is in release candidate stage; API is production-ready but not yet stable
# See: https://ort.pyke.io for latest documentation
ort = { version = "2.0.0-rc.11", optional = true }

# Async
tokio = { workspace = true, features = ["sync"] }

# Math
nalgebra = "0.34"

[dev-dependencies]
tokio = { workspace = true, features = ["rt-multi-thread", "macros"] }
pretty_assertions.workspace = true
